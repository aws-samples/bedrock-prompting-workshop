{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b010b61e-a569-43e2-97cd-e9798e79905d",
   "metadata": {},
   "source": [
    "# **Chapter 6: Precognition (Thinking Step by Step)**\n",
    "\n",
    "---\n",
    "**Lesson:**\n",
    "\n",
    "If someone woke you up and immediately started asking you several complicated questions that you had to respond to right away, how would you do? Probably not as good as if you were given time to think through your answer first. \n",
    "Guess what? Claude is the same way.\n",
    "Giving Claude time to think step by step sometimes makes Claude more accurate, particularly for complex tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062f18e-2715-463a-9db5-ca7f3f749f05",
   "metadata": {},
   "source": [
    "First we will setup our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352156f5-8b7e-4d61-b93a-c04041875177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Install dependencies\n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "%pip install --quiet langchain==0.0.304\n",
    "\n",
    "#Import libraries, and set up Bedrock client\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "#Set up model inference modifiers, and ensure Claude v2 is being called from Bedrock \n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "inference_modifier = {\n",
    "    \"max_tokens_to_sample\": 4096,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "textgen_llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2:1\",\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs=inference_modifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502384f-e01e-4249-824c-5825d67f13ea",
   "metadata": {},
   "source": [
    "# **Examples:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4ef95-74f8-4821-9af6-985608ad1fba",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Example 6.1 - Movie Review**\n",
    "\n",
    "In the movie review prompt below, it's clear to a human reader that the second sentence belies the first. But Claude takes the word \"unrelated\" too literally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a59df-b2ca-4cfd-a017-a7698b2d1d94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = textgen_llm(\"\"\"\n",
    "\n",
    "Human: Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since the year 1900.\n",
    "\n",
    "Assistant:\"\"\")\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56845631-6bf2-4bc8-ae8c-3b61024b389a",
   "metadata": {},
   "source": [
    "**Example 6.2 - Better movie review**\n",
    "\n",
    "To improve Claude's response, let's allow Claude to think things out first before answering. We do that by literally spelling out the steps that Claude should take in order to process and think through the prompt. \n",
    "Now, Claude's response is much better and more nuanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c504697-a819-49c2-848a-03d8d7223b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = textgen_llm(\"\"\"\n",
    "\n",
    "Human: Is this review sentiment positive or negative? First write the best arguments for each side in <positive-arg> and <negative-arg> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\n",
    "\n",
    "Assistant:\"\"\")\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24323c14-38c0-47ea-a657-21f8f2b8cbcc",
   "metadata": {},
   "source": [
    "**Example 6.3 - Blockbusters**\n",
    "\n",
    "Letting Claude think can shift Claude's answer from incorrect to correct. It's that simple in many cases where Claude makes mistakes!\n",
    "Let's go through an example where Claude's answer is incorrect to see how asking Claude to think can fix that.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8daf00-0356-4e06-853b-178bba21d6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = textgen_llm(\"\"\"\n",
    "\n",
    "Human: Are both directors of Jaws and Casino Royale citizens of the same country?\n",
    "\n",
    "Assistant:\"\"\")\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0a742-ae1d-43d7-9f26-34e38c5de185",
   "metadata": {},
   "source": [
    "**Example 6.4 - Blockbusters 2**\n",
    "\n",
    "Let's fix this by asking Claude to think step by step. Instead of spelling out each step for Claude, you can also simply use those exact words and ask Claude to think step by step first.\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a346d-a732-49ba-a99d-2744accec6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = textgen_llm(\"\"\"\n",
    "\n",
    "Human: Are both directors of Jaws and Casino Royale citizens of the same country? Make assumptions where needed, and think step by step.\n",
    "\n",
    "Assistant:\"\"\")\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d0390-3df1-4ef1-b9ca-7265b7ce70f9",
   "metadata": {},
   "source": [
    "**Example 6.5 - Simon says**\n",
    "\n",
    "It's important to note that to some degree, \"let's think step by step\" has been pre-built into Claude's training. You will sometimes see Claude thinking step by step even when you don't ask it to, particularly if you asked it a logic or math problem. However, even then, such techniques are not failproof, and Claude thinks step by step and still gets the wrong answer. To help Claude here, we can tell Claude exactly what process it should undertake to think through the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32980de6-b247-417c-aa0b-234194e30d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = textgen_llm(\"\"\"\n",
    "\n",
    "Human: Use the following clues to answer the following multiple-choice question, using the following procedure:\n",
    "(1) First, go through the clues one by one and consider whether the clue is potentially relevant\n",
    "(2) Second, combine the relevant clues pay attention to every single word. And then reason out the answer to the question\n",
    "(3) Third, map the answer to one of the multiple choice answers: either (a), (b), or (c)\n",
    " \n",
    "Clues:\n",
    "1. Miss Scarlett was the only person in the lounge.\n",
    "2. The person with the pipe was in the kitchen.\n",
    "3. Colonel Mustard was the only person in the observatory.\n",
    "4. Professor Plum was not in the library nor the billiard room.\n",
    "5. The person with the candlestick was in the observatory.\n",
    " \n",
    "Question: Was Colonel Mustard in the observatory with the candlestick?\n",
    "(a) Yes; Colonel Mustard was in the observatory with the candlestick\n",
    "(b) No; Colonel Mustard was not in the observatory with the candlestick\n",
    "(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick\n",
    " \n",
    "Assistant:\"\"\")\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39fef1-843f-4f29-a2dc-425b7eea9c93",
   "metadata": {},
   "source": [
    "# **Exercises**\n",
    "\n",
    "The following exercises will need you to manipulate the prompt to get the desired output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73c912-13d3-4e06-a7ac-a5cd46e9def3",
   "metadata": {},
   "source": [
    "**Exercise 6.1 - Classifying Emails**\n",
    "\n",
    "In this exercise, we'll be instructing Claude to sort emails into the following categories:\n",
    "(A) Pre-sale question\n",
    "(B) Broken or defective item\n",
    "(C) Billing question\n",
    "(D) Other (please explain)\n",
    "\n",
    "For the first part of the exercise, change the prompt in the cell below to make Claude output the correct classification. Your answer needs to include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category.\n",
    "\n",
    "> *Tip: Use precognition and other techniques you've learned leading up to this chapter!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011a614-48a0-40f7-b7a7-0932c3269ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"EMAIL\"], #Change Input variables \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please classify this email {EMAIL} \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(EMAIL=\"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\") #Should be classified as (B)\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fcfbe-45f9-4d45-91ff-e3b8399c9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"EMAIL\"], #Change Input variables \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please classify this email {EMAIL} \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(EMAIL=\"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\") #Should be classified as (A)\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e5177-1cea-46aa-9d11-597dd8883c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"EMAIL\"], #Change Input variables \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please classify this email {EMAIL} \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(EMAIL=\"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WHAT IS GOING ON???\") #Should be classified as (C)\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9835d89-6206-4db3-adb3-0b1e7cb6c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"EMAIL\"], #Change Input variables \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please classify this email {EMAIL} \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(EMAIL=\"How did I get here I am not good with computer.  Halp.\") #Should be classified as (D)\n",
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "print_ww(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e646003-3930-4d64-a340-1b56bf5b4eb6",
   "metadata": {},
   "source": [
    "# Chapter 6 - END."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
