{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b010b61e-a569-43e2-97cd-e9798e79905d",
   "metadata": {},
   "source": [
    "# **Chapter 4: Separating Data from Instructions**\n",
    "\n",
    "---\n",
    "**Lesson:**\n",
    "\n",
    "Oftentimes, we don't want to write full prompts, but instead want prompt templates that can be modified later with additional input data before submitting to Claude. This might come in handy if you want Claude to do the same thing every time, but the data that Claude uses for its task might be different each time. \n",
    "\n",
    "Luckily, we can do this pretty easily by separating the fixed skeleton of the prompt from variable user input, then substituting the user input into the prompt before sending the full prompt to Claude. \n",
    "\n",
    "Below, we'll walk step by step through how to write a substitutable prompt template, as well as how to substitute in user input.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062f18e-2715-463a-9db5-ca7f3f749f05",
   "metadata": {},
   "source": [
    "First we will setup our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352156f5-8b7e-4d61-b93a-c04041875177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Cell [1]\n",
    "\n",
    "#langchain\n",
    "%pip install langchain\n",
    "\n",
    "#Install libraries \n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "#Import libraries\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "#Set up Bedrock runtime client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "boto3_bedrock = boto3.client('bedrock')\n",
    "\n",
    "#Set up ModelID (Claude 3 Sonnet in this case)\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db465622-2627-4d7d-b3b0-bcd5f2c5e8d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cell [2]\n",
    "\n",
    "#Setup Model invocation function \n",
    "#Code modified from documentation: https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_Claude3_Text_section.html\n",
    "def get_response(prompt_data):\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "                    modelId=modelId,\n",
    "                    body=json.dumps(\n",
    "                        {\n",
    "                            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                            \"max_tokens\": 1024,\n",
    "                            \"messages\": [\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [{\"type\": \"text\", \"text\": prompt_data}],\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    ),\n",
    "                )\n",
    "    result = json.loads(response.get(\"body\").read())\n",
    "    response = result.get(\"content\", [])[0]['text']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502384f-e01e-4249-824c-5825d67f13ea",
   "metadata": {},
   "source": [
    "# **Examples:**\n",
    "\n",
    "In this first example (4.1), we're asking Claude to act as an animal noise generator. Notice that the full prompt submitted to Claude is just the prompt template substituted with the input (in this case, \"Cow\"). Notice that the word \"Cow\" replaces the \"{ANIMAL}\" section.\n",
    "\n",
    "> *Note: You don't have to call your substitution placeholder anything in particular in practice. For this example, definitely use {ANIMAL}, as that's how the exercise is formatted. But in general, just as easily, we could have called it \"{CREATURE}\" or \"{A}\" (but it's generally good to have your stand-ins be specific and relevant so that your prompt is easy to understand even without the substitution). Just make sure that whatever you name your substitution placeholder is what you use for the substitution formula.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4ef95-74f8-4821-9af6-985608ad1fba",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Example 4.1 - Moo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251a59df-b2ca-4cfd-a017-a7698b2d1d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moo.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "# Create a prompt template that has input variables\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"ANIMAL\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: I will tell you the name of an animal. Please respond with the noise that animal makes. {ANIMAL}.\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variables\n",
    "prompt = multi_var_prompt.format(ANIMAL=\"Cow\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56845631-6bf2-4bc8-ae8c-3b61024b389a",
   "metadata": {},
   "source": [
    "**Example 4.2 - This could have been an email**\n",
    "\n",
    "Why would we want to separate and substitute inputs like this? Well, prompt templates simplify repetitive tasks. Let's say you build a prompt structure that invites third party users to submit content to the prompt (in the previous example the animal whose sound they want to generate). These third party users don't have to write or even see the full prompt. All they have to do is fill in variables.\n",
    "\n",
    "We do this substitution here leverage an open source Python library called Langchain.  We use the {curly-brackets} formatting in our own code.\n",
    "\n",
    "> *Note: Prompt templates can have as many variables as desired.*\n",
    "\n",
    "When introducing substitution variables like this, it is very important to make sure Claude knows where variables start and end (vs. instructions or task descriptions). Let's look at an example where there is no separation between the instructions and the substitution variable.\t\t\n",
    "\n",
    "> *Note: We recommend that you use specifically XML tags as separators for Claude, as opposed to some other separator, as Claude's already trained to recognize XML tags in particular.\"*\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c504697-a819-49c2-848a-03d8d7223b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a more polite version of the email:\n",
      "\n",
      "<email>\n",
      "Subject: Early Morning Meeting Request\n",
      "Dear Team,\n",
      "\n",
      "I hope this email finds you well. I wanted to request an early morning meeting at 6 AM to discuss some important matters. As the CEO, I understand the inconvenience this may cause, and I appreciate your flexibility and dedication.\n",
      "\n",
      "Please let me know if you have any conflicts or concerns, and we can try to accommodate them as best as possible. Your presence and input are highly valued, and I look forward to a productive discussion.\n",
      "\n",
      "Thank you for your understanding and cooperation.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "CEO\n",
      "</email>\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"EMAIL\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Hey Claude. \n",
    "\n",
    "<email> {EMAIL} </email>\n",
    "\n",
    "Make this email more polite.\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(EMAIL=\"Show up at 6am because I'm the CEO and I say so\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24323c14-38c0-47ea-a657-21f8f2b8cbcc",
   "metadata": {},
   "source": [
    "**Example 4.3 - The farm**\n",
    "\n",
    "Let's see another example of how XML tags can help us. \n",
    "We need to surround the user input sentences in XML tags. This shows Claude where the input data begins and ends despite the misleading hyphen before \"Each is about an animal, like rabbits.\"\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8daf00-0356-4e06-853b-178bba21d6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second item on the list is \"This sentence is about spiders\".\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"SENTENCES\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: I will give you a list of sentences. \n",
    "\n",
    "-Each is about an animal, like rabbits.\n",
    "<sentences>\n",
    "{SENTENCES}\n",
    "</sentences>\n",
    "Tell me the second item on the list. \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(SENTENCES=\"\"\"\n",
    "-I like how cows sound\n",
    "-This sentence is about spiders\n",
    "-This sentence may appear to be about dogs but it's actually about pigs\"\"\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39fef1-843f-4f29-a2dc-425b7eea9c93",
   "metadata": {},
   "source": [
    "# **Exercises**\n",
    "\n",
    "The following exercises will need you to manipulate the prompt to get the desired output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73c912-13d3-4e06-a7ac-a5cd46e9def3",
   "metadata": {},
   "source": [
    "**Excercise 4.1 - Haiku Topic**\n",
    "\n",
    "Write a prompt in the highlighted template box that will take in a variable called \"{TOPIC}\" and output a haiku about the topic.\n",
    "\n",
    "Remember to format everything properly, the way we covered in earlier lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c011a614-48a0-40f7-b7a7-0932c3269ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm afraid I don't have a specific prompt to respond to since you didn't provide one. I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. Please feel free to ask me any question or provide a prompt, and I'll do my best to provide a relevant and insightful response.\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"TOPIC\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: YOUR PROMPT HERE  \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(TOPIC=\"YOUR TOPIC HERE\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab85f57-2d93-44be-ad66-eb4cf9d4651a",
   "metadata": {},
   "source": [
    "**Exercise 4.2 - Dog Question With Typos**\n",
    "\n",
    "Fix the prompt in the template below by adding XML tags, or making small edits so that Claude produces the right answer.\n",
    "\n",
    "Try not to change anything else about the prompt. The messy and mistake-ridden writing is intentional, so you can see how Claude reacts to such mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5564ad-a673-495d-ad58-0694fd5389c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm having a bit of trouble understanding your question due to the jumbled words and letters. Could you please rephrase your question about dogs more clearly? I'd be happy to try to provide a short answer once I can make out what you're asking.\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"QUESTION\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: hia its me i have a q about dogs jkaerjv {QUESTION} jklmvca tx it help me muhch much atx fst fst answer short short tx  \n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(QUESTION=\"r dogs brownw?\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e646003-3930-4d64-a340-1b56bf5b4eb6",
   "metadata": {},
   "source": [
    "# Chapter 4 - END."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
