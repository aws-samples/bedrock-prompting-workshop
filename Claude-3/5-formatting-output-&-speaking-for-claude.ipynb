{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b010b61e-a569-43e2-97cd-e9798e79905d",
   "metadata": {},
   "source": [
    "# **Chapter 5: Formatting Output & Speaking for Claude**\n",
    "\n",
    "---\n",
    "**Lesson:**\n",
    "\n",
    "Claude can format its output in a wide variety of ways. You just need to ask for it to do so!\n",
    "One of these ways is by using XML tags to separate out the response from any other superfluous text. You've already learned that you can use XML tags to make your prompt clearer and more parseable to Claude. It turns out, you can also use XML tags to make Claude's output clearer and more easily understandable to humans.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062f18e-2715-463a-9db5-ca7f3f749f05",
   "metadata": {},
   "source": [
    "First we will setup our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352156f5-8b7e-4d61-b93a-c04041875177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Cell [1]\n",
    "\n",
    "#langchain\n",
    "%pip install langchain\n",
    "\n",
    "#Install libraries \n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "#Import libraries\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "#Set up Bedrock runtime client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "boto3_bedrock = boto3.client('bedrock')\n",
    "\n",
    "#Set up ModelID (Claude 3 Sonnet in this case)\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6293a9d8-d852-4f8e-bc53-d0324143c10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cell [2]\n",
    "\n",
    "#Setup Model invocation function \n",
    "#Code modified from documentation: https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_Claude3_Text_section.html\n",
    "def get_response(prompt_data):\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "                    modelId=modelId,\n",
    "                    body=json.dumps(\n",
    "                        {\n",
    "                            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                            \"max_tokens\": 1024,\n",
    "                            \"messages\": [\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [{\"type\": \"text\", \"text\": prompt_data}],\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    ),\n",
    "                )\n",
    "    result = json.loads(response.get(\"body\").read())\n",
    "    response = result.get(\"content\", [])[0]['text']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502384f-e01e-4249-824c-5825d67f13ea",
   "metadata": {},
   "source": [
    "# **Examples:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4ef95-74f8-4821-9af6-985608ad1fba",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Example 5.1 - Tagging**\n",
    "\n",
    "Remember the 'poem preamble problem' we solved in Chapter 2 by asking Claude to skip the preamble entirely? It turns out we can also achieve a similar outcome by telling Claude to put the poem in XML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251a59df-b2ca-4cfd-a017-a7698b2d1d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haiku>\n",
      "Soft fur, twitching nose,\n",
      "Nibbling clover in the field,\n",
      "Rabbit, nature's joy.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "from langchain import PromptTemplate\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"ANIMAL\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please write a haiku about {ANIMAL}. Put it in <haiku> tags\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(ANIMAL=\"Rabbit\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56845631-6bf2-4bc8-ae8c-3b61024b389a",
   "metadata": {},
   "source": [
    "**Example 5.2 - Half Tagging**\n",
    "\n",
    "Why is this something we'd want to do? Well, having the output in XML tags allows the end user to reliably get the poem and only the poem by writing a short program to extract the content between XML tags.\t\t\n",
    "\n",
    "An extension of this technique is to put the first XML tag AFTER \"Assistant:\". When you put text after \"Assistant:\", you're basically telling Claude that Claude has already said something, and that it should continue from that point onward.\n",
    "Below, we've done this with the first \"haiku\" XML tag.\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c504697-a819-49c2-848a-03d8d7223b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haiku>\n",
      "Feline grace glides by,\n",
      "Whiskers twitching, eyes aglow,\n",
      "Purr-fect companion.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"ANIMAL\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please write a haiku about {ANIMAL}. Put it in <haiku> tags\n",
    "\n",
    "Assistant: <haiku>\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(ANIMAL=\"Cat\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24323c14-38c0-47ea-a657-21f8f2b8cbcc",
   "metadata": {},
   "source": [
    "**Example 5.3 - JSON**\n",
    "\n",
    "Claude also excels at using other output formatting styles, notably JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8daf00-0356-4e06-853b-178bba21d6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"first_line\": \"Feline grace and poise,\",\n",
      "  \"second_line\": \"Purring softly in the sun,\",\n",
      "  \"third_line\": \"Cat's quiet wisdom.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"ANIMAL\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please write a haiku about {ANIMAL}. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\"\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(ANIMAL=\"Cat\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0a742-ae1d-43d7-9f26-34e38c5de185",
   "metadata": {},
   "source": [
    "**Example 5.4 - Combination**\n",
    "\n",
    "Below is an example of multiple input variables in the same prompt AND output formatting specification, all done using XML tags.\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5a346d-a732-49ba-a99d-2744accec6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Olde English_email>\n",
      "Hail Zack, good sir! I entreat thee for a swift recounting upon the prompt thou wert tasked to indite. Let not more time be squandered, and bring word anon of thy progress on this noble endeavor.\n",
      "</Olde English_email>\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"EMAIL\",\"ADJECTIVE\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Hey Claude. Here is an email: <email>{EMAIL}</email>. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE} email> XML tags.\n",
    "\n",
    "Assistant: <{ADJECTIVE}_email>\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(EMAIL=\"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\", ADJECTIVE=\"Olde English\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39fef1-843f-4f29-a2dc-425b7eea9c93",
   "metadata": {},
   "source": [
    "# **Exercises**\n",
    "\n",
    "The following exercises will need you to manipulate the prompt to get the desired output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73c912-13d3-4e06-a7ac-a5cd46e9def3",
   "metadata": {},
   "source": [
    "**Exercise 5.1 - Steph Curry GOAT**\n",
    "\n",
    "Forced to make a choice, Claude sometimes designates Michael Jordan as the best basketball player of all time. Can we get Claude to pick someone else?\n",
    "Modify the \"best basketball player\" prompt below and use the \"speaking for Claude\" technique to make Claude make a detailed argument that the best basketball player of all time is Stephen Curry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c011a614-48a0-40f7-b7a7-0932c3269ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no definitive consensus on the best basketball player of all time, as it's a subjective matter that depends on how one weighs various factors. However, many experts and fans make a strong case for Michael Jordan being the greatest ever. Here's why:\n",
      "\n",
      "1. Unparalleled Success and Accolades:\n",
      "- 6-time NBA champion (1991, 1992, 1993, 1996, 1997, 1998)\n",
      "- 5-time NBA MVP (1988, 1991, 1992, 1996, 1998)\n",
      "- 10-time NBA scoring champion\n",
      "- Defensive Player of the Year (1988)\n",
      "- 14-time NBA All-Star\n",
      "\n",
      "2. Dominance and Impact on the Game:\n",
      "- His Airness revolutionized the game with his athleticism, skill, and competitive spirit.\n",
      "- He was a transcendent figure who made the NBA a global phenomenon.\n",
      "- His incredible scoring ability, clutch performances, and will to win set him apart.\n",
      "\n",
      "3. Iconic Moments and Legacy:\n",
      "- The Flu Game, The Shrug, The Last Shot, and many other legendary performances.\n",
      "- His impact on basketball culture, merchandise, and branding is unmatched.\n",
      "- He is arguably the most famous athlete in the world and a symbol of excellence.\n",
      "\n",
      "While players like LeBron James, Kareem Abdul-Jabbar, Wilt Chamberlain, and Bill Russell have their own compelling cases, Jordan's combination of individual brilliance, team success, and cultural impact make him the popular choice as the greatest of all time for many basketball fans and analysts.\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\"\"\"\n",
    "\n",
    "Human: Who is the overall best basketball player of all time? Make the case for one player.\n",
    "\n",
    "Assistant:\"\"\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab85f57-2d93-44be-ad66-eb4cf9d4651a",
   "metadata": {},
   "source": [
    "**Exercise 5.2 - Two Haikus**\n",
    "\n",
    "Modify the haiku prompt in the highlighted template box below and use XML tags so that Claude writes two haikus about the animal instead of just one. It should be clear where one poem ends and the other begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f5564ad-a673-495d-ad58-0694fd5389c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haiku>\n",
      "Soft paws, graceful steps,\n",
      "Purring companion, Cat,\n",
      "Ruler of the home.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"ANIMAL\"], \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please write a haiku about {ANIMAL}. Put it in <haiku> tags\n",
    "\n",
    "Assistant: <haiku>\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(ANIMAL=\"Cat\")\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1bfc7-9c61-4591-a314-f5a6a7d80bd8",
   "metadata": {},
   "source": [
    "**Exercise 5.3 - Two Haikus, Two Animals**\n",
    "\n",
    "Modify the haiku prompt in the cell below so that Claude produces two haikus about two different animals. \n",
    "Use {ANIMAL1} as a stand-in for the first substitution, and {ANIMAL2} as a stand-in for the second substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21502a9d-81a2-455a-98dd-e1b961acb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prompt template that has input variable(s)\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"ANIMAL\"], #Change Input variables \n",
    "    template=\"\"\"\n",
    "\n",
    "Human: Please write a haiku about {ANIMAL}. Put it in <haiku> tags \n",
    "\n",
    "Assistant: <haiku>\"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variable(s)\n",
    "prompt = multi_var_prompt.format(ANIMAL1=\"Cat\",ANIMAL2=\"Dog\") #We want these to be inputs to the prompt\n",
    "\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e646003-3930-4d64-a340-1b56bf5b4eb6",
   "metadata": {},
   "source": [
    "# Chapter 5 - END."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
