{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60abc38-e319-45a4-894b-b4129a24b1e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chapter 4: Prompting Techniques\n",
    "\n",
    "---\n",
    "\n",
    "**Lesson:**\n",
    "\n",
    "While we have covered the main components of what makes a prompt (positive or negative) strong, there remain a few tweeks we can make to our prompts to ensure we generate the images we desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bd69b-09b7-45a7-8020-68b7a318fdf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install dependencies\n",
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "%pip install --quiet \"pillow>=9.5,<10\"\n",
    "\n",
    "# Python Built-Ins:\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "modelId = \"stability.stable-diffusion-xl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd3acb-1b85-496f-9791-d3f587d1cb2e",
   "metadata": {},
   "source": [
    "## Keywords and the *weight* they pull\n",
    "\n",
    "There are 3 techniques central to effective keyword usage in our prompts. Let's dive into each of these one-by-one with accompanying examples.\n",
    "\n",
    "### Keyword Relevance\n",
    "\n",
    "Not all words are effective in our prompts. These words serve no purpose in our prompts other than to use up our context window, thereby limiting the number of *useful* keywords we can use. Similarly, some words, while seemingly relevant because they pertain to a specific subject, do not (yet) exist in Stable Diffusion's corpus of knowledge. At the very least, these words are so scarce in the corpus that taught Stable Diffusion that any chance they will produce useful results is of negligible probability. Let's observe with the below example.\n",
    "\n",
    "**Example 4.1 - Choose your words carefully**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3254c-223e-4172-9b49-82e91988d6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"the beautiful dog that is walking to the store in the snow and the sun shining above\"\n",
    "\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175fa948-071d-421f-b663-e6ff19adab31",
   "metadata": {},
   "source": [
    "This is quite a wordy sentence with plenty of words beyond those describing the subject and its surroundings. The question is, are these words *keywords* in the context of Stable Diffusion? We've set the seed to a specific number so we can reduce the probability of variation in our generated images and better compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906c72d-c0ea-4c8c-bb02-b228c1fcd414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt}]\n",
    "    ),\n",
    "    \"seed\": seed,\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "eg4_1a = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "eg4_1a.save(\"data/eg4_1a.png\")\n",
    "eg4_1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8eba8-b2af-4b62-a925-8cebf79f578f",
   "metadata": {},
   "source": [
    "Now, let's try a similar prompt but without the \"filler words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816e932-f160-4b78-94f4-8fbf3ed5fb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"beautiful dog, walking to store in snow, shining sun\"\n",
    "\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6e913-3311-411d-a8ee-befbfbeed9a8",
   "metadata": {},
   "source": [
    "Notice how we split the prompt into a comma-separated list since Stable Diffusion prefers lists as opposed to sentences as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efff6bd-9af3-47c6-8e56-9660402cb1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt}]\n",
    "    ),\n",
    "    \"seed\": seed,\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "eg4_1b = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "eg4_1b.save(\"data/eg4_1b.png\")\n",
    "eg4_1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf3185-3a26-4446-a63b-657475e955c9",
   "metadata": {},
   "source": [
    "### Keyword Weights\n",
    "\n",
    "Not all keywords are as important as others; this is where *weights* come into play.\n",
    "\n",
    "We can apply the syntax [{\"text\": prompt, \"weight\": factor}] to designate a weight for any given \"prompt\" variable we have defined, where factor is the weight or importance applied to the word(s) in the variable. A factor less than 1 means Stable Diffusion applies less importance to the word(s) and a factor greater than 1 means the model applies greater importance to the word(s). We have seen this applied previously where our negative prompts were applied a factor of -1.0 to signify they were negative prompts. Let's try this out.\n",
    "\n",
    "**Example 4.2 - MORE sweetrolls**\n",
    "\n",
    "In the below, we keep the weights of all keywords at default (i.e., 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71dae40-fb2c-4fc6-a027-c90d6678a689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"sweetrolls, scrumptious, glazed, large room, high ceilings\"\n",
    "\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e557a22-9c50-4c82-aa0d-aedb3ec34522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt}]\n",
    "    ),\n",
    "    \"seed\": seed,\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "eg4_2a = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "eg4_2a.save(\"data/eg4_2a.png\")\n",
    "eg4_2a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92924a7c-7877-48cb-a376-54ef5920f1ba",
   "metadata": {},
   "source": [
    "As you can see, part of the prompt was assigned precendence over the keyword \"sweetroll\" likely because Stable Diffusion \"understands\" rooms better than this specific type of food. Now, let's modify the prompt so there is more weight on sweetrolls, thereby increasing the prominance in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a0fad-fc4f-44de-9553-41dd23c3d18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt1 = \"sweetroll, scrumptious, glazed\"\n",
    "prompt2 = \"large room, high ceilings\"\n",
    "\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce51309-9177-4ea4-b6e1-c3f52286bcd7",
   "metadata": {},
   "source": [
    "Notice how we must create two separate prompts now since *weight* is applied per prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfdb3a-e238-4b6e-884f-2a4555d56750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt1, \"weight\": 3.0}]\n",
    "        + [{\"text\": prompt2}]\n",
    "    ),\n",
    "    \"seed\": seed,\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "eg4_2b = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "eg4_2b.save(\"data/eg4_2b.png\")\n",
    "eg4_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d70f66-13de-494b-a871-592262065d6d",
   "metadata": {},
   "source": [
    "We can also blend keywords via a technique called prompt scheduling. The syntax is [keyword1: keyword2: factor] and what we are doing here is controlling at which *step* in our denoising process keyword1 is switched to keyword2. For example, with factor set to 0.5 and with 30 default steps, the image would begin generation / denoising using keyword1 for steps 1-15, while we would begin \"blending\" keyword2 into the image from steps 15-30.\n",
    "\n",
    "**Example 4.3 - If Jeff Bezos and Elon Musk had a child...**\n",
    "\n",
    "Two tech titans. One image. Let's see what we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac641b7-e583-4021-b969-07da082e638d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"[Jeff Bezos:Elon Musk:0.5]\"\n",
    "\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8cd8f-b552-411c-a355-60b1c710e04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt}]\n",
    "    ),\n",
    "    \"seed\": seed,\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "eg4_3 = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "eg4_3.save(\"data/eg4_3.png\")\n",
    "eg4_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ffbbe-31c2-4ba2-8814-f2fa43aa9095",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "\n",
    "To bring together all we have learned so far, we will explore some scenarios below and see how we can develop the most optimal images.\n",
    "\n",
    "**Exercise 4.1 - Company logo**\n",
    "\n",
    "Yuo have been tasked by your organization to design a logo for a new sustainable line of products. Using proper formatting, the included parameters, detailed descriptions, negative prompting, and weights, generate a logo based on your choice of a sustainable product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b77be8-8c62-482e-b041-69de46e21771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"INSERT PROMPT\"\n",
    "negative_prompts = [\n",
    "    \"INSERT NEGATIVE PROMPT\",\n",
    "    \"INSERT NEGATIVE PROMPT\"\n",
    "]\n",
    "\n",
    "cfg_scale = \n",
    "seed = \n",
    "steps = \n",
    "style_preset =   # (e.g. photographic, digital-art, cinematic, ...)\n",
    "clip_guidance_preset =  # (e.g. FAST_BLUE FAST_GREEN NONE SIMPLE SLOW SLOWER SLOWEST)\n",
    "sampler =  # (e.g. DDIM, DDPM, K_DPMPP_SDE, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS)\n",
    "width = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547bc80-cb63-4902-bdff-d87e88ea4e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt, \"weight\": 1.0}]\n",
    "        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "    ),\n",
    "    \"cfg_scale\": cfg_scale,\n",
    "    \"seed\": seed,\n",
    "    \"steps\": steps,\n",
    "    \"style_preset\": style_preset,\n",
    "    \"clip_guidance_preset\": clip_guidance_preset,\n",
    "    \"sampler\": sampler,\n",
    "    \"width\": width\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "ex4_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "ex4_1.save(\"data/ex4_1.png\")\n",
    "ex4_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c056460-b421-4563-b6f2-8fc8d7dab829",
   "metadata": {},
   "source": [
    "**Exercise 4.2 - Capturing an image**\n",
    "\n",
    "Let's revisit this exercise for one final time. See if you can recreate an image of any particular scene in your life, be it your office, park, house, etc. Think about the details required to make this come to life, and incorporate all that we have learned at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf181387-4246-4f67-8cf6-e2fa9b95472b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"INSERT PROMPT\"\n",
    "negative_prompts = [\n",
    "    \"INSERT NEGATIVE PROMPT\",\n",
    "    \"INSERT NEGATIVE PROMPT\"\n",
    "]\n",
    "\n",
    "cfg_scale = \n",
    "seed = \n",
    "steps = \n",
    "style_preset =   # (e.g. photographic, digital-art, cinematic, ...)\n",
    "clip_guidance_preset =  # (e.g. FAST_BLUE FAST_GREEN NONE SIMPLE SLOW SLOWER SLOWEST)\n",
    "sampler =  # (e.g. DDIM, DDPM, K_DPMPP_SDE, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS)\n",
    "width = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ffebee-dd14-467a-a9c3-07d9ea72f8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"text_prompts\": (\n",
    "        [{\"text\": prompt, \"weight\": 1.0}]\n",
    "        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "    ),\n",
    "    \"cfg_scale\": cfg_scale,\n",
    "    \"seed\": seed,\n",
    "    \"steps\": steps,\n",
    "    \"style_preset\": style_preset,\n",
    "    \"clip_guidance_preset\": clip_guidance_preset,\n",
    "    \"sampler\": sampler,\n",
    "    \"width\": width\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=request, modelId=modelId)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "print(f\"{base_64_img_str[0:80]}...\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "ex4_2 = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "ex4_2.save(\"data/ex4_2.png\")\n",
    "ex4_2"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
